{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los atributos mas importante de spark es su capacidad para el procesamiento distribuido de datos ... podemos configurar nuestros scrips para que sigan nuestros parametros de funcionamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"EjemploDataFrame\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordenes_path = '../resources/ordenes.csv'\n",
    "ordenes = spark.read.csv(ordenes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambiar directamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incrementar particiones para más paralelismo\n",
    "ordenes = ordenes.repartition(10)  # Redistribuye a 10 particiones\n",
    "\n",
    "# Reducir particiones si los datos son pequeños\n",
    "ordenes = ordenes.coalesce(2)  # Combina particiones para eficiencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar los recursos para el contexto en general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MiAplicacion\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"1g\") \\\n",
    "    .config(\"spark.master\", \"spark://<master-url>:7077\") \\\n",
    "    .config(\"spark.submit.deployMode\", \"cluster\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") \\\n",
    "    .config(\"spark.network.timeout\", \"800s\") \\\n",
    "    .config(\"spark.rpc.askTimeout\", \"600s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\") \\\n",
    "    .config(\"spark.eventLog.enabled\", \"true\") \\\n",
    "    .config(\"spark.eventLog.dir\", \"hdfs://<path-to-logs>\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", \"1\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"10\") \\\n",
    "    .config(\"spark.dynamicAllocation.initialExecutors\", \"4\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.shuffle.targetPostShuffleInputSize\", \"134217728\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.6\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.5\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementos y Configuraciones de Apache Spark\n",
    "\n",
    "## 1. **Driver**\n",
    "- **¿Qué es?**  \n",
    "  El Driver es el cerebro de una aplicación Spark. Actúa como el coordinador principal, gestionando la planificación de tareas, la comunicación con los ejecutores y recopilando resultados.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.driver.memory`: Define cuánta memoria puede usar el Driver.\n",
    "  - `spark.driver.cores`: Cantidad de núcleos de CPU asignados al Driver.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Master**\n",
    "- **¿Qué es?**  \n",
    "  El Master es el gestor principal del clúster. Coordina los recursos disponibles y asigna ejecutores para las aplicaciones.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.master`: Define el tipo de clúster (local, standalone, YARN, Kubernetes, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Executors**\n",
    "- **¿Qué son?**  \n",
    "  Los ejecutores son los trabajadores que realizan el procesamiento real de datos en Spark. Ejecutan tareas y almacenan datos intermedios en memoria o disco.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.executor.instances`: Número de ejecutores a usar.\n",
    "  - `spark.executor.cores`: Cantidad de núcleos asignados por ejecutor.\n",
    "  - `spark.executor.memory`: Memoria disponible por ejecutor.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Spark SQL**\n",
    "- **¿Qué es?**  \n",
    "  Spark SQL es el módulo de Spark para trabajar con datos estructurados mediante consultas SQL. Permite optimización automática y manejo eficiente de tablas.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.sql.shuffle.partitions`: Número de particiones para operaciones de shuffle en SQL.\n",
    "  - `spark.sql.autoBroadcastJoinThreshold`: Tamaño máximo de tablas para usar joins con difusión.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Shuffle**\n",
    "- **¿Qué es?**  \n",
    "  Shuffle es el proceso de redistribuir datos entre ejecutores. Ocurre en operaciones como `groupBy`, `join` o `reduceByKey`. Es uno de los pasos más costosos en Spark.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.shuffle.compress`: Comprime los datos de shuffle.\n",
    "  - `spark.shuffle.service.enabled`: Habilita un servicio externo para manejar shuffle en clústeres con asignación dinámica.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Event Log**\n",
    "- **¿Qué es?**  \n",
    "  El Event Log almacena eventos de ejecución (tareas, etapas, errores) para análisis y monitoreo. Es útil para depurar problemas.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.eventLog.enabled`: Habilita el registro de eventos.\n",
    "  - `spark.eventLog.dir`: Directorio donde se almacenan los registros de eventos.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. **Dynamic Allocation**\n",
    "- **¿Qué es?**  \n",
    "  Ajusta automáticamente el número de ejecutores según la carga de trabajo. Ayuda a optimizar el uso de recursos en clústeres compartidos.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.dynamicAllocation.enabled`: Activa la asignación dinámica.\n",
    "  - `spark.dynamicAllocation.minExecutors`: Número mínimo de ejecutores.\n",
    "  - `spark.dynamicAllocation.maxExecutors`: Número máximo de ejecutores.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. **Storage y Cache**\n",
    "- **¿Qué es?**  \n",
    "  Spark almacena datos en memoria para acelerar operaciones repetitivas. También puede escribir datos en disco si hay limitaciones de memoria.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.storage.memoryFraction`: Porcentaje de memoria para almacenamiento en caché.\n",
    "  - `spark.memory.fraction`: Porcentaje total de memoria asignado a la ejecución y el almacenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. **Cluster Manager**\n",
    "- **¿Qué es?**  \n",
    "  Es el sistema encargado de gestionar los recursos del clúster y asignarlos a las aplicaciones Spark. Ejemplos: YARN, Mesos, Kubernetes o el propio gestor Standalone de Spark.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.deploy.mode`: Define si el Driver se ejecuta en el clúster (`cluster`) o en la máquina cliente (`client`).\n",
    "\n",
    "---\n",
    "\n",
    "## 10. **Task Scheduler**\n",
    "- **¿Qué es?**  \n",
    "  Se encarga de dividir las tareas y distribuirlas entre los ejecutores disponibles. Administra la ejecución y recuperación en caso de fallos.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.task.cpus`: Define cuántos núcleos se requieren por tarea.\n",
    "  - `spark.scheduler.mode`: Define si las tareas tienen prioridad (FIFO o FAIR).\n",
    "\n",
    "---\n",
    "\n",
    "## 11. **Broadcast**\n",
    "- **¿Qué es?**  \n",
    "  Es un mecanismo para enviar pequeñas cantidades de datos a todos los ejecutores. Es útil para evitar replicar información en cada tarea.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.broadcast.blockSize`: Tamaño de los bloques para la transmisión de datos.\n",
    "\n",
    "---\n",
    "\n",
    "## 12. **Checkpointing**\n",
    "- **¿Qué es?**  \n",
    "  Es el proceso de guardar datos intermedios en un almacenamiento persistente para tolerancia a fallos y evitar cálculos repetidos.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.checkpoint.dir`: Directorio donde se almacenan los checkpoints.\n",
    "\n",
    "---\n",
    "\n",
    "## 13. **Metrics y Monitoreo**\n",
    "- **¿Qué es?**  \n",
    "  Spark proporciona métricas para monitorear el rendimiento y el estado del clúster. Estas métricas pueden ser visualizadas en la interfaz de Spark UI o exportadas a sistemas externos.  \n",
    "  **Configuración principal:**\n",
    "  - `spark.metrics.conf`: Archivo para definir métricas personalizadas.\n",
    "  - `spark.ui.port`: Puerto para acceder a la interfaz web de Spark.\n",
    "\n",
    "---\n",
    "\n",
    "# Conclusión\n",
    "Apache Spark es un sistema flexible y poderoso para procesamiento distribuido. Cada elemento y configuración está diseñado para maximizar la eficiencia y escalabilidad en diversas aplicaciones.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
